{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOog3wpyJnaKioyCVY8ng83",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderhetal/MNIST-Handwritten-digits-classification/blob/main/Mnist_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the library"
      ],
      "metadata": {
        "id": "L6VpiW3lA_2B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D5VmOFHlvoq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import datasets , transforms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select device"
      ],
      "metadata": {
        "id": "cDx1EUiX_Lux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6TA1eea-yW7"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  DEVICE = \"cuda:0\"\n",
        "else:\n",
        " DEVICE = \"cpu\"\n",
        "device = torch.device(DEVICE)\n",
        "print(f\"Using {device} device\")\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloader :"
      ],
      "metadata": {
        "id": "kG9Tjo9cBMbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "train_dataset = torchvision.datasets.MNIST('Data', train = True, download = True, transform = transform)\n",
        "Data = torch.utils.data.DataLoader(train_dataset, batch_size = 512)"
      ],
      "metadata": {
        "id": "hAhgAE9NRjJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN model"
      ],
      "metadata": {
        "id": "MOBHYkqpBfAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layers:**\n",
        "2 convolutional layers and 3 fully connected layer\n",
        "\n",
        "**In convolutional layer 1**\n",
        "\n",
        "activation function used is ReLu ,\n",
        "Max pooling is used .\n",
        "\n",
        "**In convolutional layer 2**\n",
        "activation function used is ReLu , Max pooling is used .\n",
        "\n",
        "**3 Linear layers** with size 120,60,10 is used\n",
        "\n",
        "**For output softmax layer is used .**\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size=2)"
      ],
      "metadata": {
        "id": "JTKSnpn7BjQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.L1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.L2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.L3 = nn.Linear(7*7*64, 1000)\n",
        "    self.L4 = nn.Linear(1000, 100)\n",
        "    self.L5 = nn.Linear(100, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.L1(x)\n",
        "    out = self.L2(out)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.L3(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.L4(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.L5(out)\n",
        "    out = F.softmax(out, dim=1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "P6No5aFtVHtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tuning parameters :"
      ],
      "metadata": {
        "id": "wRsmGpG8qD2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NeuralNet = Net()\n",
        "NeuralNet = NeuralNet.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(NeuralNet.parameters(), lr=0.02, momentum = 0.9)\n",
        ""
      ],
      "metadata": {
        "id": "HMwo_BzTVKnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training :"
      ],
      "metadata": {
        "id": "8D1Ilgy3qIaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss_func = []\n",
        "accuracy = []\n",
        "\n",
        "for i in range(0,30):\n",
        "  for k, (images, labels) in enumerate(Data):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    output = NeuralNet(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss_func.append(float(loss))\n",
        "    total = labels.size(0)\n",
        "    _, predicted = torch.max(output.data , 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    acc = correct*100/total\n",
        "    accuracy.append(acc)\n",
        "    #guess = np.argmax(output.detach().numpy(), axis=1)\n",
        "    if k%10 == 0:\n",
        "      print(loss)\n",
        "      print(acc)\n",
        "      #print(labels)\n",
        "      #print(guess)\n",
        "    NeuralNet.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "mIMkSXiZVPOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NeuralNet.cpu()\n"
      ],
      "metadata": {
        "id": "VmeFATdjm-AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plots :"
      ],
      "metadata": {
        "id": "YBqrgNFxqOEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_func,\"green\")\n",
        "plt.title(\"CNN Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eBNX-qYeVSWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(accuracy,\"orange\")\n",
        "plt.title(\"CNN Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fj7X7hfQn2bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "BB_uHfrPCv-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "test_dataset = torchvision.datasets.MNIST('Data', train = False, download = True, transform = transform)\n",
        "Data_test = torch.utils.data.DataLoader(test_dataset, batch_size = 512)"
      ],
      "metadata": {
        "id": "o3z_sP6AVk3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NeuralNet.cpu()"
      ],
      "metadata": {
        "id": "qAFFAwckX7vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(Data_test):\n",
        " with torch.no_grad():\n",
        "    correct=0\n",
        "    total=0\n",
        "\n",
        "    for images,labels in Data_test:\n",
        "        outputs=NeuralNet(images)\n",
        "\n",
        "        predictions=torch.max(outputs,1)[1]\n",
        "        correct+=(predictions==labels).sum().item()\n",
        "        total+=labels.size(0)\n",
        "\n",
        "accuracy=correct/total*100\n",
        "print(\"Test Acuracy= \",accuracy)\n"
      ],
      "metadata": {
        "id": "U29wqWrhWZNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}